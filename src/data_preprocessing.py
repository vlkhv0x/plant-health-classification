"""
–ú–æ–¥—É–ª—å –¥–ª—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö PlantVillage –¥–∞—Ç–∞—Å–µ—Ç–∞
"""

import os
import numpy as np
import pandas as pd
from pathlib import Path
from PIL import Image
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
from collections import Counter
import json


class PlantDiseasePreprocessor:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö PlantVillage
    """
    
    def __init__(self, data_dir, img_size=(224, 224), batch_size=32):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
        
        Args:
            data_dir: –ø—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å –¥–∞–Ω–Ω—ã–º–∏ PlantVillage
            img_size: —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            batch_size: —Ä–∞–∑–º–µ—Ä –±–∞—Ç—á–∞
        """
        self.data_dir = Path(data_dir)
        self.img_size = img_size
        self.batch_size = batch_size
        self.class_names = []
        self.class_weights = None
        
    def load_data_paths(self):
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –ø—É—Ç–µ–π –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º –∏ –º–µ—Ç–æ–∫ –∫–ª–∞—Å—Å–æ–≤
        
        Returns:
            image_paths, labels: —Å–ø–∏—Å–∫–∏ –ø—É—Ç–µ–π –∏ –º–µ—Ç–æ–∫
        """
        image_paths = []
        labels = []
        
        print("üîç –ü–æ–∏—Å–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ...")
        
        # –°—Ç—Ä—É–∫—Ç—É—Ä–∞: data_dir/Plant___Disease/image.jpg
        for class_dir in sorted(self.data_dir.iterdir()):
            if class_dir.is_dir() and '___' in class_dir.name:
                class_name = class_dir.name
                if class_name not in self.class_names:
                    self.class_names.append(class_name)
                
                for img_file in class_dir.glob('*'):
                    if img_file.suffix.lower() in ['.jpg', '.jpeg', '.png', '.JPG']:
                        image_paths.append(str(img_file))
                        labels.append(class_name)
        
        print(f"\n‚úÖ –ù–∞–π–¥–µ–Ω–æ:")
        print(f"   –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(image_paths)}")
        print(f"   –ö–ª–∞—Å—Å–æ–≤: {len(self.class_names)}")
        
        return image_paths, labels
    
    def parse_class_info(self, class_name):
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ä–∞—Å—Ç–µ–Ω–∏–∏ –∏ –±–æ–ª–µ–∑–Ω–∏ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è –∫–ª–∞—Å—Å–∞
        
        Args:
            class_name: —Å—Ç—Ä–æ–∫–∞ –≤–∏–¥–∞ "Plant___Disease"
            
        Returns:
            dict —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        """
        parts = class_name.split('___')
        if len(parts) == 2:
            plant = parts[0].replace('_', ' ')
            disease = parts[1].replace('_', ' ')
            is_healthy = 'healthy' in disease.lower()
            return {
                'class': class_name,
                'plant': plant,
                'disease': disease,
                'is_healthy': is_healthy
            }
        return {'class': class_name, 'plant': 'Unknown', 'disease': 'Unknown', 'is_healthy': False}
    
    def create_dataframe(self, image_paths, labels):
        """
        –°–æ–∑–¥–∞–Ω–∏–µ DataFrame —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        
        Args:
            image_paths: —Å–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º
            labels: —Å–ø–∏—Å–æ–∫ –º–µ—Ç–æ–∫
            
        Returns:
            df: pandas DataFrame
        """
        print("\nüìä –°–æ–∑–¥–∞–Ω–∏–µ DataFrame...")
        
        # –ë–∞–∑–æ–≤—ã–π DataFrame
        df = pd.DataFrame({
            'filepath': image_paths,
            'class': labels
        })
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–∞—Å—Ç–µ–Ω–∏—è—Ö –∏ –±–æ–ª–µ–∑–Ω—è—Ö
        class_info = [self.parse_class_info(cls) for cls in df['class']]
        df['plant'] = [info['plant'] for info in class_info]
        df['disease'] = [info['disease'] for info in class_info]
        df['is_healthy'] = [info['is_healthy'] for info in class_info]
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        print("\nüìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–ª–∞—Å—Å–∞–º:")
        class_counts = df['class'].value_counts()
        print(f"   –í—Å–µ–≥–æ –∫–ª–∞—Å—Å–æ–≤: {len(class_counts)}")
        print(f"   Min samples per class: {class_counts.min()}")
        print(f"   Max samples per class: {class_counts.max()}")
        print(f"   Mean samples per class: {class_counts.mean():.1f}")
        
        print("\nüå± –†–∞—Å—Ç–µ–Ω–∏—è –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ:")
        print(df['plant'].value_counts())
        
        print("\nü¶† –ó–¥–æ—Ä–æ–≤—ã–µ vs –ë–æ–ª—å–Ω—ã–µ:")
        print(df['is_healthy'].value_counts())
        
        return df
    
    def calculate_class_weights(self, df):
        """
        –†–∞—Å—á—ë—Ç –≤–µ—Å–æ–≤ –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è –±–æ—Ä—å–±—ã —Å –¥–∏—Å–±–∞–ª–∞–Ω—Å–æ–º
        
        Args:
            df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
            
        Returns:
            class_weights: —Å–ª–æ–≤–∞—Ä—å –≤–µ—Å–æ–≤
        """
        class_counts = df['class'].value_counts()
        total = len(df)
        
        # Inverse frequency weighting
        class_weights = {}
        for idx, class_name in enumerate(sorted(class_counts.index)):
            count = class_counts[class_name]
            weight = total / (len(class_counts) * count)
            class_weights[idx] = weight
        
        print(f"\n‚öñÔ∏è  –í–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω—ã")
        print(f"   Min weight: {min(class_weights.values()):.4f}")
        print(f"   Max weight: {max(class_weights.values()):.4f}")
        
        self.class_weights = class_weights
        return class_weights
    
    def split_data(self, df, test_size=0.15, val_size=0.15, random_state=42):
        """
        –°—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        
        Args:
            df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
            test_size: –¥–æ–ª—è —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏
            val_size: –¥–æ–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏
            random_state: seed
            
        Returns:
            train_df, val_df, test_df
        """
        print(f"\n‚úÇÔ∏è  –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö...")
        
        # –û—Ç–¥–µ–ª—è–µ–º test
        train_val_df, test_df = train_test_split(
            df,
            test_size=test_size,
            random_state=random_state,
            stratify=df['class']
        )
        
        # –û—Ç–¥–µ–ª—è–µ–º validation
        val_size_adjusted = val_size / (1 - test_size)
        train_df, val_df = train_test_split(
            train_val_df,
            test_size=val_size_adjusted,
            random_state=random_state,
            stratify=train_val_df['class']
        )
        
        print(f"   Train: {len(train_df)} ({len(train_df)/len(df)*100:.1f}%)")
        print(f"   Val: {len(val_df)} ({len(val_df)/len(df)*100:.1f}%)")
        print(f"   Test: {len(test_df)} ({len(test_df)/len(df)*100:.1f}%)")
        
        return train_df, val_df, test_df
    
    def create_data_generators(self, train_df, val_df, test_df, 
                               augmentation=True, augment_rare_classes=False):
        """
        –°–æ–∑–¥–∞–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö
        
        Args:
            train_df, val_df, test_df: DataFrames
            augmentation: –ø—Ä–∏–º–µ–Ω—è—Ç—å –ª–∏ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—é
            augment_rare_classes: —É—Å–∏–ª–µ–Ω–Ω–∞—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –¥–ª—è —Ä–µ–¥–∫–∏—Ö –∫–ª–∞—Å—Å–æ–≤
            
        Returns:
            train_generator, val_generator, test_generator
        """
        print(f"\nüîÑ –°–æ–∑–¥–∞–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö...")
        print(f"   –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è: {'‚úì' if augmentation else '‚úó'}")
        print(f"   –£—Å–∏–ª–µ–Ω–Ω–∞—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è —Ä–µ–¥–∫–∏—Ö –∫–ª–∞—Å—Å–æ–≤: {'‚úì' if augment_rare_classes else '‚úó'}")
        
        # –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –¥–ª—è –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏
        if augmentation:
            train_datagen = ImageDataGenerator(
                rescale=1./255,
                rotation_range=20,
                width_shift_range=0.1,
                height_shift_range=0.1,
                shear_range=0.1,
                zoom_range=0.15,
                horizontal_flip=True,
                vertical_flip=True,
                brightness_range=[0.8, 1.2],
                fill_mode='nearest'
            )
        else:
            train_datagen = ImageDataGenerator(rescale=1./255)
        
        # –¢–æ–ª—å–∫–æ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è val/test
        val_test_datagen = ImageDataGenerator(rescale=1./255)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤
        train_generator = train_datagen.flow_from_dataframe(
            train_df,
            x_col='filepath',
            y_col='class',
            target_size=self.img_size,
            batch_size=self.batch_size,
            class_mode='categorical',
            shuffle=True,
            seed=42
        )
        
        val_generator = val_test_datagen.flow_from_dataframe(
            val_df,
            x_col='filepath',
            y_col='class',
            target_size=self.img_size,
            batch_size=self.batch_size,
            class_mode='categorical',
            shuffle=False
        )
        
        test_generator = val_test_datagen.flow_from_dataframe(
            test_df,
            x_col='filepath',
            y_col='class',
            target_size=self.img_size,
            batch_size=self.batch_size,
            class_mode='categorical',
            shuffle=False
        )
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–∞–ø–ø–∏–Ω–≥–∞ –∫–ª–∞—Å—Å–æ–≤
        self.class_indices = train_generator.class_indices
        self.save_class_mapping()
        
        print(f"\n‚úÖ –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä—ã —Å–æ–∑–¥–∞–Ω—ã")
        print(f"   –ö–ª–∞—Å—Å–æ–≤: {len(train_generator.class_indices)}")
        print(f"   –ë–∞—Ç—á–µ–π –≤ train: {len(train_generator)}")
        print(f"   –ë–∞—Ç—á–µ–π –≤ val: {len(val_generator)}")
        print(f"   –ë–∞—Ç—á–µ–π –≤ test: {len(test_generator)}")
        
        return train_generator, val_generator, test_generator
    
    def save_class_mapping(self, save_path='data/processed/class_mapping.json'):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–∞–ø–ø–∏–Ω–≥–∞ –∫–ª–∞—Å—Å–æ–≤"""
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        
        # –°–æ–∑–¥–∞—ë–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –º–∞–ø–ø–∏–Ω–≥ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        extended_mapping = {}
        for class_name, idx in self.class_indices.items():
            info = self.parse_class_info(class_name)
            extended_mapping[idx] = {
                'class_name': class_name,
                'plant': info['plant'],
                'disease': info['disease'],
                'is_healthy': info['is_healthy']
            }
        
        with open(save_path, 'w') as f:
            json.dump(extended_mapping, f, indent=4)
        
        print(f"üíæ –ú–∞–ø–ø–∏–Ω–≥ –∫–ª–∞—Å—Å–æ–≤ —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {save_path}")
    
    def prepare_data_pipeline(self, augment_rare_classes=False):
        """
        –ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö
        
        Returns:
            train_gen, val_gen, test_gen, class_weights
        """
        print("=" * 70)
        print("üåø –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• PLANTVILLAGE")
        print("=" * 70)
        
        # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –ø—É—Ç–µ–π
        image_paths, labels = self.load_data_paths()
        
        # 2. –°–æ–∑–¥–∞–Ω–∏–µ DataFrame
        df = self.create_dataframe(image_paths, labels)
        
        # 3. –†–∞—Å—á—ë—Ç –≤–µ—Å–æ–≤ –∫–ª–∞—Å—Å–æ–≤
        class_weights = self.calculate_class_weights(df)
        
        # 4. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        train_df, val_df, test_df = self.split_data(df)
        
        # 5. –°–æ–∑–¥–∞–Ω–∏–µ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤
        train_gen, val_gen, test_gen = self.create_data_generators(
            train_df, val_df, test_df,
            augmentation=True,
            augment_rare_classes=augment_rare_classes
        )
        
        print("\n" + "=" * 70)
        print("‚úÖ –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• –ó–ê–í–ï–†–®–ï–ù–ê")
        print("=" * 70)
        
        return train_gen, val_gen, test_gen, class_weights


def load_and_preprocess_image(image_path, img_size=(224, 224)):
    """
    –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    
    Args:
        image_path: –ø—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
        img_size: —Ä–∞–∑–º–µ—Ä
        
    Returns:
        preprocessed_image
    """
    img = Image.open(image_path).convert('RGB')
    img = img.resize(img_size)
    img_array = np.array(img) / 255.0
    return img_array


if __name__ == "__main__":
    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    preprocessor = PlantDiseasePreprocessor(
        data_dir='data/raw/PlantVillage',
        img_size=(224, 224),
        batch_size=32
    )
    
    train_gen, val_gen, test_gen, class_weights = preprocessor.prepare_data_pipeline()
    
    print("\n‚úÖ –ü–∞–π–ø–ª–∞–π–Ω –≥–æ—Ç–æ–≤ –∫ –æ–±—É—á–µ–Ω–∏—é!")
