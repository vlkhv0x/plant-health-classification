"""
–ú–æ–¥—É–ª—å —Å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –±–æ–ª–µ–∑–Ω–µ–π —Ä–∞—Å—Ç–µ–Ω–∏–π
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models
from tensorflow.keras.applications import (
    EfficientNetB3, ResNet50, DenseNet121, MobileNetV2
)
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import (
    EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard
)
import os
from datetime import datetime


class PlantDiseaseModel:
    """
    –ö–ª–∞—Å—Å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –±–æ–ª–µ–∑–Ω–µ–π —Ä–∞—Å—Ç–µ–Ω–∏–π
    """
    
    def __init__(self, num_classes, img_size=(224, 224), model_type='efficientnetb3'):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
        
        Args:
            num_classes: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤
            img_size: —Ä–∞–∑–º–µ—Ä –≤—Ö–æ–¥–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            model_type: —Ç–∏–ø –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏
        """
        self.num_classes = num_classes
        self.img_size = img_size
        self.model_type = model_type
        self.model = None
        
    def build_model(self, trainable_base=False):
        """
        –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        
        Args:
            trainable_base: –¥–µ–ª–∞—Ç—å –ª–∏ –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å trainable
            
        Returns:
            model: —Å–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
        """
        input_shape = (*self.img_size, 3)
        
        # –í—ã–±–æ—Ä –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏
        if self.model_type == 'efficientnetb3':
            base_model = EfficientNetB3(
                weights='imagenet',
                include_top=False,
                input_shape=input_shape
            )
        elif self.model_type == 'resnet50':
            base_model = ResNet50(
                weights='imagenet',
                include_top=False,
                input_shape=input_shape
            )
        elif self.model_type == 'densenet121':
            base_model = DenseNet121(
                weights='imagenet',
                include_top=False,
                input_shape=input_shape
            )
        elif self.model_type == 'mobilenetv2':
            base_model = MobileNetV2(
                weights='imagenet',
                include_top=False,
                input_shape=input_shape
            )
        else:
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –º–æ–¥–µ–ª–∏: {self.model_type}")
        
        # –ó–∞–º–æ—Ä–æ–∑–∫–∞ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏
        base_model.trainable = trainable_base
        
        # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–π –º–æ–¥–µ–ª–∏
        inputs = keras.Input(shape=input_shape)
        
        # –ë–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å
        x = base_model(inputs, training=False)
        
        # Global Average Pooling
        x = layers.GlobalAveragePooling2D()(x)
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ Dense —Å–ª–æ–∏
        x = layers.Dense(256, activation='relu', name='dense_1')(x)
        x = layers.BatchNormalization()(x)
        x = layers.Dropout(0.4)(x)
        
        x = layers.Dense(128, activation='relu', name='dense_2')(x)
        x = layers.BatchNormalization()(x)
        x = layers.Dropout(0.3)(x)
        
        # Output layer
        outputs = layers.Dense(
            self.num_classes, 
            activation='softmax',
            name='output'
        )(x)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
        model = keras.Model(inputs=inputs, outputs=outputs, name=f'{self.model_type}_plant_disease')
        
        self.model = model
        return model
    
    def compile_model(self, learning_rate=0.0001, class_weights=None):
        """
        –ö–æ–º–ø–∏–ª—è—Ü–∏—è –º–æ–¥–µ–ª–∏
        
        Args:
            learning_rate: learning rate
            class_weights: –≤–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è –±–æ—Ä—å–±—ã —Å –¥–∏—Å–±–∞–ª–∞–Ω—Å–æ–º
        """
        if self.model is None:
            raise ValueError("–°–Ω–∞—á–∞–ª–∞ —Å–æ–∑–¥–∞–π—Ç–µ –º–æ–¥–µ–ª—å —Å build_model()")
        
        # –ú–µ—Ç—Ä–∏–∫–∏
        metrics = [
            'accuracy',
            keras.metrics.TopKCategoricalAccuracy(k=3, name='top_3_accuracy'),
            keras.metrics.Precision(name='precision'),
            keras.metrics.Recall(name='recall')
        ]
        
        self.model.compile(
            optimizer=Adam(learning_rate=learning_rate),
            loss='categorical_crossentropy',
            metrics=metrics
        )
        
        self.class_weights = class_weights
        print("‚úÖ –ú–æ–¥–µ–ª—å —Å–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω–∞")
        
    def get_callbacks(self, checkpoint_path='models/best_model.h5', 
                     use_tensorboard=False):
        """
        –°–æ–∑–¥–∞–Ω–∏–µ callbacks
        
        Args:
            checkpoint_path: –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
            use_tensorboard: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ TensorBoard
            
        Returns:
            —Å–ø–∏—Å–æ–∫ callbacks
        """
        callbacks = [
            # Early Stopping
            EarlyStopping(
                monitor='val_loss',
                patience=10,
                restore_best_weights=True,
                verbose=1
            ),
            
            # Model Checkpoint
            ModelCheckpoint(
                filepath=checkpoint_path,
                monitor='val_accuracy',
                save_best_only=True,
                verbose=1
            ),
            
            # Reduce Learning Rate
            ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.5,
                patience=5,
                min_lr=1e-7,
                verbose=1
            )
        ]
        
        # TensorBoard (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        if use_tensorboard:
            log_dir = os.path.join('logs', datetime.now().strftime("%Y%m%d-%H%M%S"))
            callbacks.append(
                TensorBoard(log_dir=log_dir, histogram_freq=1)
            )
        
        return callbacks
    
    def train(self, train_generator, val_generator, epochs=30, 
             callbacks=None, use_class_weights=True):
        """
        –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        
        Args:
            train_generator: –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
            val_generator: –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            epochs: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö
            callbacks: —Å–ø–∏—Å–æ–∫ callbacks
            use_class_weights: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ª–∏ –≤–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤
            
        Returns:
            history: –∏—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è
        """
        if self.model is None:
            raise ValueError("–°–Ω–∞—á–∞–ª–∞ —Å–æ–∑–¥–∞–π—Ç–µ –∏ —Å–∫–æ–º–ø–∏–ª–∏—Ä—É–π—Ç–µ –º–æ–¥–µ–ª—å")
        
        if callbacks is None:
            callbacks = self.get_callbacks()
        
        print(f"\nüöÄ –ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ {self.model_type}")
        print(f"   –≠–ø–æ—Ö–∏: {epochs}")
        print(f"   –ö–ª–∞—Å—Å–æ–≤: {self.num_classes}")
        print(f"   Train batches: {len(train_generator)}")
        print(f"   Val batches: {len(val_generator)}")
        print(f"   –í–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤: {'‚úì' if use_class_weights and self.class_weights else '‚úó'}")
        
        history = self.model.fit(
            train_generator,
            validation_data=val_generator,
            epochs=epochs,
            callbacks=callbacks,
            class_weight=self.class_weights if use_class_weights else None,
            verbose=1
        )
        
        print("\n‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        
        return history
    
    def fine_tune(self, train_generator, val_generator, epochs=15,
                 unfreeze_layers=50, learning_rate=1e-5):
        """
        Fine-tuning –º–æ–¥–µ–ª–∏
        
        Args:
            train_generator: –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
            val_generator: –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            epochs: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö
            unfreeze_layers: —Å–∫–æ–ª—å–∫–æ —Å–ª–æ—ë–≤ —Ä–∞–∑–º–æ—Ä–æ–∑–∏—Ç—å
            learning_rate: learning rate
            
        Returns:
            history: –∏—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è
        """
        print(f"\nüîß Fine-tuning: —Ä–∞–∑–º–æ—Ä–∞–∂–∏–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ {unfreeze_layers} —Å–ª–æ—ë–≤")
        
        # –ü–æ–ª—É—á–∞–µ–º –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å
        base_model = self.model.layers[1]
        base_model.trainable = True
        
        # –ó–∞–º–æ—Ä–∞–∂–∏–≤–∞–µ–º –≤—Å–µ –∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö N —Å–ª–æ—ë–≤
        for layer in base_model.layers[:-unfreeze_layers]:
            layer.trainable = False
        
        # –ü–µ—Ä–µ–∫–æ–º–ø–∏–ª—è—Ü–∏—è —Å –º–µ–Ω—å—à–∏–º learning rate
        self.model.compile(
            optimizer=Adam(learning_rate=learning_rate),
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        # –û–±—É—á–µ–Ω–∏–µ
        history = self.model.fit(
            train_generator,
            validation_data=val_generator,
            epochs=epochs,
            callbacks=self.get_callbacks(checkpoint_path='models/finetuned_model.h5'),
            class_weight=self.class_weights,
            verbose=1
        )
        
        print("\n‚úÖ Fine-tuning –∑–∞–≤–µ—Ä—à—ë–Ω!")
        
        return history
    
    def summary(self):
        """–í—ã–≤–æ–¥ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –º–æ–¥–µ–ª–∏"""
        if self.model is None:
            raise ValueError("–°–Ω–∞—á–∞–ª–∞ —Å–æ–∑–¥–∞–π—Ç–µ –º–æ–¥–µ–ª—å")
        return self.model.summary()
    
    def save_model(self, filepath='models/final_model.h5'):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        if self.model is None:
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ —Å–æ–∑–¥–∞–Ω–∞")
        
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        self.model.save(filepath)
        print(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {filepath}")
    
    @staticmethod
    def load_model(filepath):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        return keras.models.load_model(filepath)
    
    def get_layer_names(self):
        """–ü–æ–ª—É—á–∏—Ç—å –∏–º–µ–Ω–∞ –≤—Å–µ—Ö —Å–ª–æ—ë–≤"""
        if self.model is None:
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ —Å–æ–∑–¥–∞–Ω–∞")
        return [layer.name for layer in self.model.layers]


if __name__ == "__main__":
    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    num_classes = 38  # PlantVillage –∏–º–µ–µ—Ç 38 –∫–ª–∞—Å—Å–æ–≤
    
    model_builder = PlantDiseaseModel(
        num_classes=num_classes,
        img_size=(224, 224),
        model_type='efficientnetb3'
    )
    
    model = model_builder.build_model()
    model_builder.compile_model()
    
    print("\nüìä –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏:")
    model_builder.summary()
    
    print(f"\n‚úÖ –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤ –º–æ–¥–µ–ª–∏: {model.count_params():,}")
