"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –±–æ–ª–µ–∑–Ω–µ–π —Ä–∞—Å—Ç–µ–Ω–∏–π
"""

import os
import sys
import argparse
import json
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix
import tensorflow as tf

sys.path.append('src')

from data_preprocessing import PlantDiseasePreprocessor
from utils import plot_confusion_matrix, plot_sample_predictions


def parse_args():
    parser = argparse.ArgumentParser(description='–û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏')
    parser.add_argument('--model_path', type=str, default='models/best_model.h5')
    parser.add_argument('--data_dir', type=str, default='data/raw/PlantVillage')
    parser.add_argument('--batch_size', type=int, default=32)
    parser.add_argument('--detailed_analysis', action='store_true')
    return parser.parse_args()


def main():
    args = parse_args()
    
    print("=" * 80)
    print("üìä –û–¶–ï–ù–ö–ê –ú–û–î–ï–õ–ò")
    print("=" * 80)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    print(f"\nüì• –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏: {args.model_path}")
    model = tf.keras.models.load_model(args.model_path)
    print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    with open('models/config.json', 'r') as f:
        config = json.load(f)
    class_names = config['class_names']
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    print("\nüìä –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
    preprocessor = PlantDiseasePreprocessor(
        data_dir=args.data_dir,
        img_size=(config['img_size'], config['img_size']),
        batch_size=args.batch_size
    )
    
    image_paths, labels = preprocessor.load_data_paths()
    df = preprocessor.create_dataframe(image_paths, labels)
    train_df, val_df, test_df = preprocessor.split_data(df)
    _, _, test_gen = preprocessor.create_data_generators(train_df, val_df, test_df)
    
    # –û—Ü–µ–Ω–∫–∞
    print("\nüîÆ –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π...")
    test_gen.reset()
    predictions = model.predict(test_gen, verbose=1)
    y_pred = np.argmax(predictions, axis=1)
    y_true = test_gen.classes
    
    # –ú–µ—Ç—Ä–∏–∫–∏
    test_loss, test_accuracy = model.evaluate(test_gen, verbose=0)
    
    print("\n" + "=" * 80)
    print("üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´")
    print("=" * 80)
    print(f"\nTest Loss: {test_loss:.4f}")
    print(f"Test Accuracy: {test_accuracy:.4f}")
    
    # Classification report
    report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)
    
    print(f"\nPrecision (weighted): {report['weighted avg']['precision']:.4f}")
    print(f"Recall (weighted): {report['weighted avg']['recall']:.4f}")
    print(f"F1-Score (weighted): {report['weighted avg']['f1-score']:.4f}")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    results = {
        'test_loss': float(test_loss),
        'test_accuracy': float(test_accuracy),
        'classification_report': report,
        'confusion_matrix': confusion_matrix(y_true, y_pred).tolist()
    }
    
    with open('reports/evaluation_results.json', 'w') as f:
        json.dump(results, f, indent=4)
    
    # Classification report –≤ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
    with open('reports/classification_report.txt', 'w') as f:
        f.write(classification_report(y_true, y_pred, target_names=class_names))
    
    print("\n‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã")
    
    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
    cm = confusion_matrix(y_true, y_pred)
    plot_confusion_matrix(cm, class_names)
    plot_sample_predictions(model, test_gen, class_names)
    
    print("\n" + "=" * 80)


if __name__ == "__main__":
    main()
